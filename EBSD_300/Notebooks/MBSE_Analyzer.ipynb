{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef785c9-a1c0-4ad7-a185-02a1569ca072",
   "metadata": {},
   "source": [
    "# Model Based System Engineering Analyzer: \n",
    "## Leveraging AI for System Engineering models \n",
    "\n",
    "Welcome to the **MBSE Assistant Analyzer Notebook**, a powerful tool designed to augment your ability to review, comprehend, and enhance system models with AI-driven support. This notebook integrates a variety of capabilities to assist with:\n",
    "\n",
    "1. **Model Review and Comprehension**:\n",
    "   - Gain deeper insights into the structure and behavior of your system model.\n",
    "   - Use AI to clarify relationships, dependencies, and interactions within the model.\n",
    "\n",
    "2. **Impact Analysis**:\n",
    "   - Explore the potential effects of component failures on the system.\n",
    "   - Simulate scenarios to identify vulnerabilities and design improvements.\n",
    "\n",
    "3. **Simulation Generation**:\n",
    "   - Automatically generate simulations based on the model's architecture and behaviors.\n",
    "   - Use simulations for validation, testing, and demonstration purposes.\n",
    "\n",
    "4. **Failure Analysis**:\n",
    "   - Assess the system's resilience under various failure conditions.\n",
    "   - Extract meaningful insights to strengthen reliability and performance.\n",
    "\n",
    "5. **Content Extraction for Downstream Domains**:\n",
    "   - Convert model data into formats suitable for use in other engineering domains.\n",
    "   - Facilitate seamless collaboration across teams and tools.\n",
    "\n",
    "This notebook serves as a comprehensive platform to bridge the gap between system models and actionable insights, empowering architects to make informed decisions and design robust solutions. Whether you're investigating enhancements, running failure simulations, or preparing data for external domains, this assistant streamlines the process with AI-enhanced guidance.\n",
    "\n",
    "Feel free to explore and adapt the prompts and models to suit your specific use case. Let‚Äôs dive in and unlock the potential of your system model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acc178-1a94-4014-b1f7-13c97a9ba4ec",
   "metadata": {},
   "source": [
    "### Model-Specific Code (Do Not Modify)\n",
    "\n",
    "This section contains code that is specific to the system model. It is updated only when the model is changed and should not require user modifications under normal circumstances.\n",
    "\n",
    "If a new model is introduced, ensure this section is reviewed and updated as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ba8743-5dac-41be-9083-d44aa0199411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/tkSDISW/Capella_Tools \n",
    "import capellambse.decl\n",
    "\n",
    "from capella_tools import capellambse_helper\n",
    "\n",
    "\n",
    "from IPython import display as diag_display\n",
    "resources = {\n",
    "    \"EBSD_300\": \"EBSD_300/EBSD_300\",\n",
    "}\n",
    "path_to_model = \"../EBSD_300.aird\"\n",
    "model = capellambse.MelodyModel(path_to_model, resources=resources)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73131d-3ba3-4c6f-8418-378d418156a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e07f65-caa7-4e20-9268-7c5df4783e36",
   "metadata": {},
   "source": [
    "## üîÑ Embedding Generation Process\n",
    "\n",
    "### Overview\n",
    "This section generates embeddings, which streamlines processing and analyzing the model. The embeddings provide a structured representation of the data that powers subsequent tasks and visualizations.\n",
    "\n",
    "### When is this step necessary?\n",
    "- **Initial Run:** If this notebook is being run for the first time, embeddings will need to be generated.\n",
    "- **Model Updates:** If the underlying model has been modified, regenerating embeddings ensures the data remains accurate and up-to-date.\n",
    "\n",
    "### Important Notes\n",
    "- **Duration:** This process may take **a minute or more** to complete, depending on the size and complexity of the model.\n",
    "- **Output:** Upon completion, embeddings will be ready for use in subsequent sections of the notebook.\n",
    "\n",
    "### Instructions\n",
    "1. Ensure the required model is loaded.\n",
    "2. Run the cell below to initiate the embedding generation process.\n",
    "3. Wait for the process to complete before proceeding.\n",
    "\n",
    "> üí° **Tip:** You can monitor progress in the notebook's output cell. If any errors occur, check that the model is properly configured and accessible.\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ö†Ô∏è **Warning:** Interrupting this step may result in incomplete or invalid embeddings. If interrupted, re-run the cell to restart the process.\n",
    "\n",
    "---\n",
    "\n",
    "Continue to the next cell to generate embeddings. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c54cb77-76e8-4309-90e0-7da1d2a2d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EmbeddingManager initialized\n",
      "üîê API Key: Loaded from secrets\n",
      "üåê Base URL: https://api.openai.com/v1\n",
      "ü§ñ Model: gpt-4o\n",
      "‚ÑπÔ∏è Model file newer than embeddings: ../EBSD_300.aird\n",
      "Creating Embeddings\n",
      "embeddings generated\n",
      "Saving embeddings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from capella_tools  import capella_embeddings_manager\n",
    "\n",
    "# Generate embeddings for all objects\n",
    "model_embedding_manager = capella_embeddings_manager.EmbeddingManager()\n",
    "\n",
    "embedding_file = \"embeddings.json\" \n",
    "model_embedding_manager.set_files( path_to_model , embedding_file)\n",
    "\n",
    "model_embedding_manager.create_model_embeddings(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671a45d-5335-463c-802a-156296f21ad4",
   "metadata": {},
   "source": [
    "## üéØ Prompt for System Model Element Analysis\n",
    "\n",
    "### Purpose\n",
    "This cell accepts a prompt to identify and isolate the specific object(s) to be analyzed. Providing detailed and accurate information in the prompt will ensure the best performance during the analysis.\n",
    "\n",
    "### What to Include in Your Prompt\n",
    "For optimal results, specify the following details about the object(s):\n",
    "1. **Type of ARCADIA Object:** Clearly state the type of the object (e.g., Logical Component, Physical Component, Functional Exchange).\n",
    "2. **Name of the Object:** Provide the exact name of the object as defined in the model.\n",
    "3. **ARCADIA Phase:** Specify the phase associated with the object (e.g., Operational Analysis, System Analysis, Logical Architecture, Physical Architecture).\n",
    "4. **Related Objects:** Identify any objects connected via exchanges or dependencies.\n",
    "\n",
    "### Example Prompt\n",
    "Locate the Logical Component named Brake Pedal in the Logical phase and has a Driver supplying input.\n",
    "### ‚úÖ Tips for Success\n",
    "- **Use precise terminology:** Ensure your prompt aligns with the model's structure and terminology.\n",
    "- **Include related objects:** Whenever possible, specify related objects to enhance context and improve analysis accuracy.\n",
    "- **Double-check details:** Verify object names and phases to ensure they match the model exactly.\n",
    "'''\n",
    "\n",
    "### üöÄ Next Steps\n",
    "1. Run the cell below.\n",
    "2. Enter your prompt, providing the necessary details as outlined above.\n",
    "3. Wait for the analysis to complete.\n",
    "4. Select the best index or indexes for analysis. (The last selection will drive selection of a prompt.)\n",
    "\n",
    "> üí° **Tip:** If you're unsure about the model structure, review the documentation or refer to the model's diagrams for additional guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31298768-f6da-4f27-9c76-50d02b7a0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is a list of ranked Objects Based on Query:\n",
      "Index: 0, Name: [OAB] All, Similarity: 0.64, Type: Diagram, Phase: Operational Analysis OA, Source: , Target: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_objects = model_embedding_manager.query_and_select_top_objects(\"[OAB] All\", top_n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4a6ad-39a9-4bc3-ae26-5d97c5fe394b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## üìù Generate Structured Input File \n",
    "\n",
    "### Purpose\n",
    "This cell generates a structured structured input file, `capella_model.yaml`, which serves as input for prompts tailored to the object type of the last selected item. This ensures that the prompt aligns with the model's structure and provides accurate context for analysis.\n",
    "\n",
    "### What This Cell Does\n",
    "- Extracts data related to the elements selected.\n",
    "- Structures the data into a YAML format.\n",
    "- Saves the YAML file as `capella_model.yaml` for further use.\n",
    "\n",
    "### Key Features\n",
    "- The YAML file includes:\n",
    "  - **Object Type:** The type of the element.\n",
    "  - **Object Details:** Attributes, relationships, and associated exchanges.\n",
    "  - **Structured Input:** Designed to enhance prompt accuracy and model analysis.\n",
    "\n",
    "### Instructions\n",
    "1. Run this cell to create the `capella_model.yaml` file.\n",
    "2. Ensure the last selected item is correctly identified to avoid mismatched data.\n",
    "3. Use the generated YAML file as structured input for tailored prompts in subsequent steps.\n",
    "\n",
    "### Notes\n",
    "- The file will be saved in the current working directory.\n",
    "- If the selected object changes, re-run this cell to update the YAML file.\n",
    "\n",
    "> üí° **Tip:** Review the contents of `capella_model.yaml` if needed to ensure accuracy and completeness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db8d5ea-0e49-4098-aedc-0914d956f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workflow\n",
    "from capella_tools import capellambse_yaml_manager\n",
    "yaml_handler = capellambse_yaml_manager.CapellaYAMLHandler()\n",
    "   \n",
    "#Generate YAML for the logical component and append to the file\n",
    "for object in  selected_objects : \n",
    "    yaml_handler.generate_yaml(model.by_uuid(object[\"uuid\"]))  \n",
    "\n",
    "\n",
    "\n",
    "#yaml_handler.display()\n",
    "yaml_handler.generate_yaml_referenced_objects()\n",
    "#yaml_handler.display()\n",
    "\n",
    "yaml_handler.write_output_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113cb97-36e1-46b4-aec7-9713aea09a64",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Generate Contextual Diagram\n",
    "\n",
    "### Purpose\n",
    "This cell generates a **contextual diagram** for the selected object. The diagram visually represents the object's relationships and interactions, providing a clear and comprehensive view of its context within the model.\n",
    "\n",
    "### Supported Object Types\n",
    "This functionality works the following ARCADIA elements, including:\n",
    "- **Functions**\n",
    "- **Activities**\n",
    "- **Components**\n",
    "- **Entities**\n",
    "- **Exchanges and Interactions**\n",
    "- **Physical Links**\n",
    "\n",
    "### What This Cell Does\n",
    "- Identifies the selected object.\n",
    "- Extracts relevant relationships, exchanges, and dependencies.\n",
    "- Creates a contextual diagram based on the object's type and its connections.\n",
    "\n",
    "### Instructions\n",
    "1. Ensure the object is correctly selected in the previous step.\n",
    "2. Run this cell to generate the contextual diagram.\n",
    "3. Review the output to verify accuracy and completeness.\n",
    "\n",
    "### Key Benefits\n",
    "- **Clarity:** Visualizes how the selected object interacts with other model elements.\n",
    "- **Versatility:** Works seamlessly across ARCADIA functions, activities, components, and entities.\n",
    "- **Actionable Insight:** Helps identify key dependencies and relationships for analysis.\n",
    "\n",
    "### Notes\n",
    "- The diagram will be displayed below upon completion.\n",
    "- If the selected object changes, re-run this cell to update the contextual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6679d117-2c29-4dc1-9eac-b14e602b1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for object in  selected_objects : \n",
    "    #print(object)\n",
    "    if object[\"type\"] == \"Diagram\" :\n",
    "        diagram = model.by_uuid(object[\"uuid\"])\n",
    "        #display(diagram)\n",
    "    else:\n",
    "        obj = model.by_uuid(object[\"uuid\"])\n",
    "        capellambse_helper.display_context_diagram(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed6cc0-6c32-4f80-8a39-1dccfaca5eb5",
   "metadata": {},
   "source": [
    "## üí¨ Predefined Prompts for Analysis\n",
    "\n",
    "### Purpose\n",
    "This cell contains predefined prompts for analyzing different types of ARCADIA elements, including components, functions, operational processes, and a default prompt. You can use these as-is or tailor them to suit your specific needs.\n",
    "\n",
    "\n",
    "### Instructions\n",
    "1. The appropriate prompt will be used for your analysis needs.\n",
    "2. Modify the prompt to include additional details or requirements, if necessary.\n",
    "\n",
    "### Notes\n",
    "- Predefined prompts are designed to guide analysis and ensure consistency.\n",
    "- Tailoring the prompts allows you to focus on specific aspects of the model relevant to your use case.\n",
    "\n",
    "> üí° **Tip:** Save your tailored prompts for reuse in similar analyses or workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24590371-907b-4e64-898f-99c5e9499460",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_prompt = \"\"\"\n",
    "Please analyze the yaml file and display the result as .html and specifically provide insights on:\n",
    "1. The purpose of the component.\n",
    "2. Any components that make it up.\n",
    "3. A list of allocated functions and their potential roles.\n",
    "4. How the ports relate to the functions.\n",
    "5. Any traceabilty artifacts linked to the component and the artifacts url.\n",
    "6. Suggestions for improving the component description.\n",
    "7. Create a tabular table with columns for the component and its ports and the port interfaces, the interface souce and the interface target.\n",
    "8. List any property values and the related model element.\n",
    "9. A summary of any related state machines.\n",
    "\"\"\"\n",
    "function_prompt = \"\"\"\n",
    "Please analyze the yaml file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the function.\n",
    "2. Its owning component.\n",
    "4. Any ports relate to the functions.\n",
    "5. Any traceabilty artifacts linked to the component and the artifacts url.\n",
    "6. Suggestions for improving the function description.\n",
    "7. Create a tabular table with columns for the owning component, this function, its ports and the functional exchanges.\n",
    "\"\"\"\n",
    "activity_prompt = \"\"\"\n",
    "Please analyze the yaml file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the activity.\n",
    "2. Its actor or entiry.\n",
    "4. Any traceabilty artifacts linked to the component and the artifacts url.\n",
    "7. Suggestions for improving the activity description.\n",
    "7. Create a tabular table with columns for the owning entity or actor, this activity, its exchanges.\n",
    "\"\"\"\n",
    "functional_chain_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the functional chain.\n",
    "2. A table with first column being the owning component, the second being a function, last column being involved functional exchange, organized by involved functional exchanges.\n",
    "3. Any traceabilty artifacts linked to functional chain, functions, owning component and the traceability artifacts url.\n",
    "4. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "operational_process_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the operation process.\n",
    "2. A table with first column being the owning component, the second being a activities, last column being involved activity exchange, organized by involved activity exchanges.\n",
    "3. Any traceabilty artifacts linked to the operational process chain, activities, owning component and the traceability artifacts url.\n",
    "4. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "diagram_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the diagram based on its related nodes.\n",
    "2. Describe what the nodes represent in the ARCADIA method and what the diagram is describing.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "default_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the primary component listed first in the yaml file.=.\n",
    "2. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e82f3-a07b-404e-a230-7ebcf690e3e4",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Execute Default Prompts\n",
    "\n",
    "### Purpose\n",
    "This cell executes the **default prompts** defined for analyzing the model. These prompts are designed to provide general insights and overviews when specific object types or contexts are not explicitly defined.\n",
    "\n",
    "### What This Cell Does\n",
    "- Reads the structured input file (e.g., `capella_model.yaml`).\n",
    "- Uses the default prompts to query key details about the selected object(s).\n",
    "- Outputs the results directly in the notebook.\n",
    "\n",
    "### üõ†Ô∏è Instructions\n",
    "1. Ensure the `capella_model.yaml` file is generated and up-to-date.\n",
    "2. Run this cell to execute the default prompts.\n",
    "3. Review the output to verify the accuracy and relevance of the analysis.\n",
    "\n",
    "### üìù Notes\n",
    "- The default prompts are **general-purpose** and may not capture all details specific to certain object types.\n",
    "- For more tailored analysis, consider using prompts designed for specific ARCADIA elements.\n",
    "\n",
    "> üí° **Tip:** Use the default prompts as a starting point, then refine or modify them based on your analysis needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf53953-bfae-4677-9f45-906e72aa93e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "‚úÖ ChatGPTAnalyzer initialized\n",
      "üîê API Key: Loaded from secrets\n",
      "üåê Base URL: https://api.openai.com/v1\n",
      "ü§ñ Model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Your prompt:** \n",
       "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
       "1. The purpose of the diagram based on its related nodes.\n",
       "2. Describe what the nodes represent in the ARCADIA method and what the diagram is describing.\n",
       "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
       " Format the response in .html format."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
       "<title>YAML Analysis</title>\n",
       "\n",
       "</head>\n",
       "<body>\n",
       "<h1>YAML File Analysis</h1>\n",
       "<h2>1. Purpose of the Diagram</h2>\n",
       "<p>The diagram named '[OAB] All' is a comprehensive representation of the system's operational activities and interactions. Its primary purpose is to enhance the accuracy of thermal simulation models by calibrating them with real-world measurement data. This is achieved through a series of interconnected nodes that represent various operational activities, entities, and functional exchanges.</p>\n",
       "<p>The diagram involves activities such as measuring junction temperatures, applying power steps, launching power step tests, performing analyses, and monitoring degradation. These activities are crucial for ensuring the reliability and efficiency of electronic components by simulating and testing their thermal performance under different conditions.</p>\n",
       "<h2>2. Nodes Representation in ARCADIA Method</h2>\n",
       "<p>In the ARCADIA method, nodes in the diagram represent different elements of the system architecture, including:</p>\n",
       "<ul>\n",
       "<li><strong>Entities:</strong> These are the components or actors within the system, such as 'EBSD Software Application', 'EBSD Hardware', and 'EBSD User'. They are responsible for executing specific activities or processes.</li>\n",
       "<li><strong>Operational Activities:</strong> These nodes represent the tasks or operations performed by the entities. Examples include 'Measure Junction Temperatures', 'Apply Power Step', and 'Perform EOL Testing'. These activities are essential for achieving the system's objectives.</li>\n",
       "<li><strong>Functional Exchanges:</strong> These nodes describe the interactions or data flows between different activities or entities. For instance, 'User Interactions', 'Gather Data', and 'Drive System' are functional exchanges that facilitate communication and data transfer within the system.</li>\n",
       "</ul>\n",
       "<p>The diagram effectively describes the system's operational processes, highlighting the interactions between different components and activities. It provides a clear overview of how thermal testing and simulation are conducted, ensuring that electronic components meet the required performance standards.</p>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Token Usage Info:**\n",
       "\n",
       "Tokens used: prompt=13869, completion=590, total=14459"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "#from capella_tools  import Open_AI_RAG_manager\n",
    "\n",
    "from capella_tools import Open_AI_RAG_manager\n",
    "#print(object)\n",
    "if object[\"type\"] ==  \"LogicalComponent\" or object[\"type\"] ==  \"SystemComponent\" or object[\"type\"] ==  \"PhysicalComponent-BEHAVIOR\"  or object[\"type\"] ==  \"PhysicalComponent-NODE\" :\n",
    "    prompt = component_prompt\n",
    "elif object[\"type\"] ==  \"FunctionalChain\" :  \n",
    "    prompt = functional_chain_prompt\n",
    "elif object[\"type\"] ==  \"OperationalProcess\":  \n",
    "    prompt = functional_chain_prompt\n",
    "elif object[\"type\"] ==  \"SystemFuntion\" or object[\"type\"] ==  \"LogicalFunction\" or object[\"type\"] ==  \"PhysicalFunction\":\n",
    "    prompt = function_prompt\n",
    "elif object[\"type\"] ==  \"OperationalActivity\" : \n",
    "    prompt = activity_prompt\n",
    "elif object[\"type\"] ==  \"Diagram\" : \n",
    "    prompt = diagram_prompt\n",
    "else :\n",
    "    prompt = default_prompt    \n",
    "\n",
    "\n",
    "# Step 1: Get YAML content\n",
    "yaml_content = yaml_handler.get_yaml_content()\n",
    "\n",
    "# Step 2: Invoke ChatGPT for analysis\n",
    "analyzer = Open_AI_RAG_manager.ChatGPTAnalyzer(yaml_content)\n",
    "analyzer.initial_prompt(prompt)\n",
    "chatgpt_response = analyzer.get_response()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab07e0f-6cdb-4b16-9c5b-0acd3e7944cd",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Execute Followup Prompts\n",
    "\n",
    "### Purpose\n",
    "This cell executes the **follow up prompts** defined for analyzing the model. These prompts can be added by the note book user in addition to the default prompts\n",
    "\n",
    "### What This Cell Does\n",
    "- Use the structured input file (e.g., `capella_model.yaml`).\n",
    "- Excutes the prompt defined in the cell.\n",
    "- Outputs the results directly in the notebook.\n",
    "\n",
    "### üõ†Ô∏è Instructions\n",
    "1. Ensure the `capella_model.yaml` file is generated and up-to-date.\n",
    "2. Run this cell to execute the default prompts.\n",
    "3. Review the output to verify the accuracy and relevance of the analysis.\n",
    "\n",
    "> üí° **Tip:** Modify the promt to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab94bcf-5ea3-4d7d-89e8-508dcd603d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Your prompt:** \n",
       "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
       "1. The purpose of all the operational processes.\n",
       "2. A table with first column being the owning component, the second being a activities, last column being involved activity exchange, organized by involved activity exchanges.\n",
       "3. Any traceabilty artifacts linked to the operational process chain, activities, owning component and the traceability artifacts url.\n",
       "4. List any property values and the related model element.\n",
       "Please format the analysis in .html suitable for Juypter Notbook display operation.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
       "<title>YAML File Analysis</title>\n",
       "\n",
       "</head>\n",
       "<body>\n",
       "<h1>YAML File Analysis</h1>\n",
       "<h2>1. Purpose of All Operational Processes</h2>\n",
       "<ul>\n",
       "<li><strong>Detailed Thermal Characterization:</strong> This process involves measuring junction temperatures, initiating thermal testing, and collecting thermal data to provide a comprehensive understanding of the thermal characteristics of electronic components.</li>\n",
       "<li><strong>Quick and Easy Testing:</strong> Utilizes thermal transient testing methods that are easy to apply, even for complex designs, and suitable for high-volume testing.</li>\n",
       "<li><strong>Automated Quality Assurance:</strong> Integrates with production lines for end-of-line testing, ensuring zero-defect production through automated thermal testing and quality binning.</li>\n",
       "<li><strong>Gather Triggers:</strong> Involves monitoring test requests and triggering quality tests to ensure that all necessary conditions are met before proceeding with further testing.</li>\n",
       "<li><strong>Active Power Cycling:</strong> Focuses on performing active power cycling and monitoring degradation to assess the durability and reliability of electronic components under power cycling conditions.</li>\n",
       "<li><strong>Simulation Model Calibration:</strong> Involves preparing and creating simulation data, receiving calibration data, and performing analysis to ensure that simulation models accurately reflect real-world conditions.</li>\n",
       "</ul>\n",
       "<h2>2. Activities and Involved Activity Exchanges</h2>\n",
       "<table>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>Owning Component</th>\n",
       "<th>Activities</th>\n",
       "<th>Involved Activity Exchange</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Measure Junction Temperatures</td>\n",
       "<td>User Interactions, Action, Measure, Monitor</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Apply Power Step</td>\n",
       "<td>Acrion, Drive, Drive Power</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Launch Power Step Test</td>\n",
       "<td>User interaction, Acrion, Action</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Perform Analysis</td>\n",
       "<td>Analysis, Data, Analyze, Gather Analysis Data</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Perform EOL Testing</td>\n",
       "<td>User Interaction, Gather Test Request, Analyze, Drive, Measure</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Perform Active Power Cycling</td>\n",
       "<td>User Interaction, Monitor, Drive Power</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Monitor Degradation</td>\n",
       "<td>Monitor</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Software Application</td>\n",
       "<td>Prepare Simulation Data</td>\n",
       "<td>Intraction, Simulaton Data, Gather Analysis Data</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Hardware</td>\n",
       "<td>Collect Thermal Data</td>\n",
       "<td>Gather Data, Themal Data</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Hardware</td>\n",
       "<td>Drive Hardware Under Test with Power</td>\n",
       "<td>Drive System, Stimulus</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD Hardware</td>\n",
       "<td>Monitor Test Request</td>\n",
       "<td>Test Request, Gather Test Request</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD User</td>\n",
       "<td>Initiate Thermal Testing</td>\n",
       "<td>User Interactions, Next</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD User</td>\n",
       "<td>Start Transient Testing</td>\n",
       "<td>User interaction, Next</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD User</td>\n",
       "<td>Analyze Data</td>\n",
       "<td>Analysis</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD User</td>\n",
       "<td>Enable Quality Test</td>\n",
       "<td>User Interaction</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD User</td>\n",
       "<td>Initiate Power Cycling</td>\n",
       "<td>User Interaction</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>EBSD User</td>\n",
       "<td>Create Simulation Data</td>\n",
       "<td>Intraction</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Simulation Models</td>\n",
       "<td>Receive Calibration Data</td>\n",
       "<td>Simulaton Data</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>System Under Test</td>\n",
       "<td>Provide Source of Measurement</td>\n",
       "<td>Themal Data</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>System Under Test</td>\n",
       "<td>Receive Stimulus</td>\n",
       "<td>Stimulus</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<h2>3. Traceability Artifacts</h2>\n",
       "<p>Currently, the YAML file does not explicitly mention any traceability artifacts or URLs linked to the operational process chain, activities, owning components, or traceability artifacts. This information might be available in a different part of the system documentation or external resources.</p>\n",
       "<h2>4. Property Values and Related Model Elements</h2>\n",
       "<ul>\n",
       "<li><strong>primary_uuid:</strong> Unique identifier for each model element, such as operational activities, entities, and functional exchanges.</li>\n",
       "<li><strong>description:</strong> Provides a brief overview or purpose of the model element, such as operational activities and processes.</li>\n",
       "<li><strong>is_human:</strong> Indicates whether an entity is human or not, applicable to entities like 'EBSD User'.</li>\n",
       "<li><strong>is_actor:</strong> Indicates whether an entity acts as an actor in the system, applicable to entities like 'EBSD User'.</li>\n",
       "</ul>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Token Usage Info:**\n",
       "\n",
       "Tokens used: prompt=14579, completion=1637, total=16216"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_operational_process_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of all the operational processes.\n",
    "2. A table with first column being the owning component, the second being a activities, last column being involved activity exchange, organized by involved activity exchanges.\n",
    "3. Any traceabilty artifacts linked to the operational process chain, activities, owning component and the traceability artifacts url.\n",
    "4. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "\n",
    "analyzer.follow_up_prompt(all_operational_process_prompt )\n",
    "chatgpt_response = analyzer.get_response()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ada9b-367c-4929-badf-e27c7170b825",
   "metadata": {},
   "source": [
    "## üí¨ Launch Interactive Chat on Structured Input\n",
    "\n",
    "### Purpose\n",
    "This cell launches an interactive chat session based on the structured input file, leveraging ARCADIA and Polarion terminology to ensure the analysis remains consistent with the modeling context.\n",
    "\n",
    "### Key Features\n",
    "- Uses the generated structured input file (e.g., `capella_model.yaml`) to guide the conversation.\n",
    "- Supports ARCADIA terms such as **functions**, **components**, **activities**, and **exchanges**.\n",
    "- Incorporates Polarion terms like **workitem**, **requirement**, and **traceability** for seamless integration with requirements management workflows.\n",
    "\n",
    "### How It Works\n",
    "1. The structured input file provides context for the chat session.\n",
    "2. You can interactively query details about the model elements, relationships, and dependencies.\n",
    "3. Responses are tailored using ARCADIA and Polarion terminology.\n",
    "\n",
    "### Example Prompts\n",
    "- **For ARCADIA:**\n",
    "  ```plaintext\n",
    "  What are the dependencies and exchanges for the selected function in the Logical Architecture phase?\n",
    "\n",
    "- **For Polarion:**\n",
    "  ```plaintext\n",
    "  Provide the traceability matrix for the workitem linked to this component.\n",
    "  ```\n",
    "### üõ†Ô∏è Instructions\n",
    "1. Ensure the `capella_model.yaml` file has been generated and is up-to-date.\n",
    "2. Run this cell to start the interactive chat session.\n",
    "3. Enter your queries using **ARCADIA** or **Polarion** terms for accurate and relevant responses.\n",
    "\n",
    "### üìù Notes\n",
    "- The interactive chat dynamically adapts to the content in the structured input file.\n",
    "- Use precise and contextual queries to ensure the best results and insights.\n",
    "\n",
    "> üí° **Tip:** If you're unfamiliar with ARCADIA or Polarion terminology, consult the respective documentation or glossary for guidance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654576ab-fb68-45e8-bf4c-1931c1c0c9ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ScannerError",
     "evalue": "mapping values are not allowed here\n  in \"<unicode string>\", line 394, column 18:\n             ref_uuid: f6116b94-7b01-499a-be14-5786c0 ... \n                     ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapella_model.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     yaml_content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 6\u001b[0m n2 \u001b[38;5;241m=\u001b[39m \u001b[43mN2DiagramGenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN2DiagramGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLAB Brake Diagram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctional\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m n2\u001b[38;5;241m.\u001b[39mrun_all()\n\u001b[1;32m     10\u001b[0m n2 \u001b[38;5;241m=\u001b[39m N2DiagramGenerator\u001b[38;5;241m.\u001b[39mN2DiagramGenerator(yaml_content, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAB Brake Diagram\u001b[39m\u001b[38;5;124m\"\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/capella_tools/N2DiagramGenerator.py:29\u001b[0m, in \u001b[0;36mN2DiagramGenerator.__init__\u001b[0;34m(self, yaml_content, diagram_name, mode)\u001b[0m\n\u001b[1;32m     26\u001b[0m yaml\u001b[38;5;241m.\u001b[39madd_constructor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!uuid\u001b[39m\u001b[38;5;124m\"\u001b[39m, uuid_constructor, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mSafeLoader)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiagram_name \u001b[38;5;241m=\u001b[39m diagram_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Exchange Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaml_data \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msafe_load\u001b[39m(stream):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    to be safe for untrusted input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[0;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     80\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[0;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m     84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:111\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    109\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceEndEvent):\n\u001b[0;32m--> 111\u001b[0m     node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    113\u001b[0m end_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     80\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[0;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m     84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:110\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors[anchor] \u001b[38;5;241m=\u001b[39m node\n\u001b[1;32m    109\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSequenceEndEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    111\u001b[0m     node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, index))\n\u001b[1;32m    112\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/parser.py:382\u001b[0m, in \u001b[0;36mParser.parse_block_sequence_entry\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_block_sequence_entry\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBlockEntryToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    383\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(BlockEntryToken, BlockEndToken):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mchoices):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_more_tokens():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens:\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/scanner.py:223\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Is it the value indicator?\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_value():\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Is it an alias?\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/scanner.py:577\u001b[0m, in \u001b[0;36mScanner.fetch_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# We are allowed to start a complex value if and only if\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# we can start a simple key.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_simple_key:\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmapping values are not allowed here\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mark())\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# If this value starts a new block mapping, we need to add\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# BLOCK-MAPPING-START.  It will be detected as an error later by\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# the parser.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n",
      "\u001b[0;31mScannerError\u001b[0m: mapping values are not allowed here\n  in \"<unicode string>\", line 394, column 18:\n             ref_uuid: f6116b94-7b01-499a-be14-5786c0 ... \n                     ^"
     ]
    }
   ],
   "source": [
    "from capella_tools  import N2DiagramGenerator\n",
    "# Example: Using the class with YAML content and a diagram name\n",
    "with open(\"capella_model.yaml\", \"r\") as f:\n",
    "    yaml_content = f.read()\n",
    "\n",
    "n2 = N2DiagramGenerator.N2DiagramGenerator(yaml_content, \"LAB Brake Diagram\",mode=\"functional\" )\n",
    "n2.run_all()\n",
    "\n",
    "\n",
    "n2 = N2DiagramGenerator.N2DiagramGenerator(yaml_content, \"LAB Brake Diagram\",mode=\"component\")\n",
    "n2.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d370a-fcf4-4084-9064-f5e11a03a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.interactive_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dea895-123c-4c7f-b386-89510fcfcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2484d-c283-416d-b5ae-03289fc2a8a1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c59542-ddf7-4047-9007-2613a7f96589",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddd2fe-aeef-43a8-94d2-4b7cac1ce700",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
