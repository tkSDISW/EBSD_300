{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef785c9-a1c0-4ad7-a185-02a1569ca072",
   "metadata": {},
   "source": [
    "# Model Based System Engineering Analyzer: \n",
    "## Leveraging AI for System Engineering models \n",
    "\n",
    "Welcome to the **MBSE Assistant Analyzer Notebook**, a powerful tool designed to augment your ability to review, comprehend, and enhance system models with AI-driven support. This notebook integrates a variety of capabilities to assist with:\n",
    "\n",
    "1. **Model Review and Comprehension**:\n",
    "   - Gain deeper insights into the structure and behavior of your system model.\n",
    "   - Use AI to clarify relationships, dependencies, and interactions within the model.\n",
    "\n",
    "2. **Impact Analysis**:\n",
    "   - Explore the potential effects of component failures on the system.\n",
    "   - Simulate scenarios to identify vulnerabilities and design improvements.\n",
    "\n",
    "3. **Simulation Generation**:\n",
    "   - Automatically generate simulations based on the model's architecture and behaviors.\n",
    "   - Use simulations for validation, testing, and demonstration purposes.\n",
    "\n",
    "4. **Failure Analysis**:\n",
    "   - Assess the system's resilience under various failure conditions.\n",
    "   - Extract meaningful insights to strengthen reliability and performance.\n",
    "\n",
    "5. **Content Extraction for Downstream Domains**:\n",
    "   - Convert model data into formats suitable for use in other engineering domains.\n",
    "   - Facilitate seamless collaboration across teams and tools.\n",
    "\n",
    "This notebook serves as a comprehensive platform to bridge the gap between system models and actionable insights, empowering architects to make informed decisions and design robust solutions. Whether you're investigating enhancements, running failure simulations, or preparing data for external domains, this assistant streamlines the process with AI-enhanced guidance.\n",
    "\n",
    "Feel free to explore and adapt the prompts and models to suit your specific use case. Let‚Äôs dive in and unlock the potential of your system model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acc178-1a94-4014-b1f7-13c97a9ba4ec",
   "metadata": {},
   "source": [
    "### Model-Specific Code (Do Not Modify)\n",
    "\n",
    "This section contains code that is specific to the system model. It is updated only when the model is changed and should not require user modifications under normal circumstances.\n",
    "\n",
    "If a new model is introduced, ensure this section is reviewed and updated as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ba8743-5dac-41be-9083-d44aa0199411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/tkSDISW/Capella_Tools \n",
    "import capellambse.decl\n",
    "\n",
    "from capella_tools import capellambse_helper\n",
    "\n",
    "\n",
    "from IPython import display as diag_display\n",
    "resources = {\n",
    "    \"EBSD_300\": \"EBSD_300/EBSD_300\",\n",
    "}\n",
    "path_to_model = \"../EBSD_300.aird\"\n",
    "model = capellambse.MelodyModel(path_to_model, resources=resources)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73131d-3ba3-4c6f-8418-378d418156a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e07f65-caa7-4e20-9268-7c5df4783e36",
   "metadata": {},
   "source": [
    "## üîÑ Embedding Generation Process\n",
    "\n",
    "### Overview\n",
    "This section generates embeddings, which streamlines processing and analyzing the model. The embeddings provide a structured representation of the data that powers subsequent tasks and visualizations.\n",
    "\n",
    "### When is this step necessary?\n",
    "- **Initial Run:** If this notebook is being run for the first time, embeddings will need to be generated.\n",
    "- **Model Updates:** If the underlying model has been modified, regenerating embeddings ensures the data remains accurate and up-to-date.\n",
    "\n",
    "### Important Notes\n",
    "- **Duration:** This process may take **a minute or more** to complete, depending on the size and complexity of the model.\n",
    "- **Output:** Upon completion, embeddings will be ready for use in subsequent sections of the notebook.\n",
    "\n",
    "### Instructions\n",
    "1. Ensure the required model is loaded.\n",
    "2. Run the cell below to initiate the embedding generation process.\n",
    "3. Wait for the process to complete before proceeding.\n",
    "\n",
    "> üí° **Tip:** You can monitor progress in the notebook's output cell. If any errors occur, check that the model is properly configured and accessible.\n",
    "\n",
    "---\n",
    "\n",
    "> ‚ö†Ô∏è **Warning:** Interrupting this step may result in incomplete or invalid embeddings. If interrupted, re-run the cell to restart the process.\n",
    "\n",
    "---\n",
    "\n",
    "Continue to the next cell to generate embeddings. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c54cb77-76e8-4309-90e0-7da1d2a2d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EmbeddingManager initialized\n",
      "üîê API Key: Loaded from secrets\n",
      "üåê Base URL: https://api.openai.com/v1\n",
      "ü§ñ Model: gpt-4o\n",
      "‚ùå Embedding file not found. A new one will be created.\n",
      "Creating Embeddings\n",
      "embeddings generated\n",
      "Saving embeddings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from capella_tools  import capella_embeddings_manager\n",
    "\n",
    "# Generate embeddings for all objects\n",
    "model_embedding_manager = capella_embeddings_manager.EmbeddingManager()\n",
    "\n",
    "embedding_file = \"embeddings.json\" \n",
    "model_embedding_manager.set_files( path_to_model , embedding_file)\n",
    "\n",
    "model_embedding_manager.create_model_embeddings(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671a45d-5335-463c-802a-156296f21ad4",
   "metadata": {},
   "source": [
    "## üéØ Prompt for System Model Element Analysis\n",
    "\n",
    "### Purpose\n",
    "This cell accepts a prompt to identify and isolate the specific object(s) to be analyzed. Providing detailed and accurate information in the prompt will ensure the best performance during the analysis.\n",
    "\n",
    "### What to Include in Your Prompt\n",
    "For optimal results, specify the following details about the object(s):\n",
    "1. **Type of ARCADIA Object:** Clearly state the type of the object (e.g., Logical Component, Physical Component, Functional Exchange).\n",
    "2. **Name of the Object:** Provide the exact name of the object as defined in the model.\n",
    "3. **ARCADIA Phase:** Specify the phase associated with the object (e.g., Operational Analysis, System Analysis, Logical Architecture, Physical Architecture).\n",
    "4. **Related Objects:** Identify any objects connected via exchanges or dependencies.\n",
    "\n",
    "### Example Prompt\n",
    "Locate the Logical Component named Brake Pedal in the Logical phase and has a Driver supplying input.\n",
    "### ‚úÖ Tips for Success\n",
    "- **Use precise terminology:** Ensure your prompt aligns with the model's structure and terminology.\n",
    "- **Include related objects:** Whenever possible, specify related objects to enhance context and improve analysis accuracy.\n",
    "- **Double-check details:** Verify object names and phases to ensure they match the model exactly.\n",
    "'''\n",
    "\n",
    "### üöÄ Next Steps\n",
    "1. Run the cell below.\n",
    "2. Enter your prompt, providing the necessary details as outlined above.\n",
    "3. Wait for the analysis to complete.\n",
    "4. Select the best index or indexes for analysis. (The last selection will drive selection of a prompt.)\n",
    "\n",
    "> üí° **Tip:** If you're unsure about the model structure, review the documentation or refer to the model's diagrams for additional guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31298768-f6da-4f27-9c76-50d02b7a0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is a list of ranked Objects Based on Query:\n",
      "Index: 0, Name: [OCB] Operational Capabilities, Similarity: 0.78, Type: Diagram, Phase: Operational Analysis OA, Source: , Target: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_objects = model_embedding_manager.query_and_select_top_objects(\"OCB] Operational Capabilities\", top_n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4a6ad-39a9-4bc3-ae26-5d97c5fe394b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## üìù Generate Structured Input File \n",
    "\n",
    "### Purpose\n",
    "This cell generates a structured structured input file, `capella_model.yaml`, which serves as input for prompts tailored to the object type of the last selected item. This ensures that the prompt aligns with the model's structure and provides accurate context for analysis.\n",
    "\n",
    "### What This Cell Does\n",
    "- Extracts data related to the elements selected.\n",
    "- Structures the data into a YAML format.\n",
    "- Saves the YAML file as `capella_model.yaml` for further use.\n",
    "\n",
    "### Key Features\n",
    "- The YAML file includes:\n",
    "  - **Object Type:** The type of the element.\n",
    "  - **Object Details:** Attributes, relationships, and associated exchanges.\n",
    "  - **Structured Input:** Designed to enhance prompt accuracy and model analysis.\n",
    "\n",
    "### Instructions\n",
    "1. Run this cell to create the `capella_model.yaml` file.\n",
    "2. Ensure the last selected item is correctly identified to avoid mismatched data.\n",
    "3. Use the generated YAML file as structured input for tailored prompts in subsequent steps.\n",
    "\n",
    "### Notes\n",
    "- The file will be saved in the current working directory.\n",
    "- If the selected object changes, re-run this cell to update the YAML file.\n",
    "\n",
    "> üí° **Tip:** Review the contents of `capella_model.yaml` if needed to ensure accuracy and completeness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db8d5ea-0e49-4098-aedc-0914d956f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workflow\n",
    "from capella_tools import capellambse_yaml_manager\n",
    "yaml_handler = capellambse_yaml_manager.CapellaYAMLHandler()\n",
    "   \n",
    "#Generate YAML for the logical component and append to the file\n",
    "for object in  selected_objects : \n",
    "    yaml_handler.generate_yaml(model.by_uuid(object[\"uuid\"]))  \n",
    "\n",
    "\n",
    "#yaml_handler.display()\n",
    "yaml_handler.generate_yaml_referenced_objects()\n",
    "#yaml_handler.display()\n",
    "\n",
    "yaml_handler.write_output_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113cb97-36e1-46b4-aec7-9713aea09a64",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Generate Contextual Diagram\n",
    "\n",
    "### Purpose\n",
    "This cell generates a **contextual diagram** for the selected object. The diagram visually represents the object's relationships and interactions, providing a clear and comprehensive view of its context within the model.\n",
    "\n",
    "### Supported Object Types\n",
    "This functionality works the following ARCADIA elements, including:\n",
    "- **Functions**\n",
    "- **Activities**\n",
    "- **Components**\n",
    "- **Entities**\n",
    "- **Exchanges and Interactions**\n",
    "- **Physical Links**\n",
    "\n",
    "### What This Cell Does\n",
    "- Identifies the selected object.\n",
    "- Extracts relevant relationships, exchanges, and dependencies.\n",
    "- Creates a contextual diagram based on the object's type and its connections.\n",
    "\n",
    "### Instructions\n",
    "1. Ensure the object is correctly selected in the previous step.\n",
    "2. Run this cell to generate the contextual diagram.\n",
    "3. Review the output to verify accuracy and completeness.\n",
    "\n",
    "### Key Benefits\n",
    "- **Clarity:** Visualizes how the selected object interacts with other model elements.\n",
    "- **Versatility:** Works seamlessly across ARCADIA functions, activities, components, and entities.\n",
    "- **Actionable Insight:** Helps identify key dependencies and relationships for analysis.\n",
    "\n",
    "### Notes\n",
    "- The diagram will be displayed below upon completion.\n",
    "- If the selected object changes, re-run this cell to update the contextual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6679d117-2c29-4dc1-9eac-b14e602b1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for object in  selected_objects : \n",
    "    #print(object)\n",
    "    if object[\"type\"] == \"Diagram\" :\n",
    "        diagram = model.by_uuid(object[\"uuid\"])\n",
    "        #display(diagram)\n",
    "    else:\n",
    "        obj = model.by_uuid(object[\"uuid\"])\n",
    "        capellambse_helper.display_context_diagram(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e82f3-a07b-404e-a230-7ebcf690e3e4",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Execute Default Prompts\n",
    "\n",
    "### Purpose\n",
    "This cell executes the **default prompts** defined for analyzing the model. These prompts are designed to provide general insights and overviews when specific object types or contexts are not explicitly defined.\n",
    "\n",
    "### What This Cell Does\n",
    "- Reads the structured input file (e.g., `capella_model.yaml`).\n",
    "- Uses the default prompts to query key details about the selected object(s).\n",
    "- Outputs the results directly in the notebook.\n",
    "\n",
    "### üõ†Ô∏è Instructions\n",
    "1. Ensure the `capella_model.yaml` file is generated and up-to-date.\n",
    "2. Run this cell to execute the default prompts.\n",
    "3. Review the output to verify the accuracy and relevance of the analysis.\n",
    "\n",
    "### üìù Notes\n",
    "- The default prompts are **general-purpose** and may not capture all details specific to certain object types.\n",
    "- For more tailored analysis, consider using prompts designed for specific ARCADIA elements.\n",
    "\n",
    "> üí° **Tip:** Use the default prompts as a starting point, then refine or modify them based on your analysis needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf53953-bfae-4677-9f45-906e72aa93e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChatGPTAnalyzer initialized\n",
      "üîê API Key: Loaded from secrets\n",
      "üåê Base URL: https://api.openai.com/v1\n",
      "ü§ñ Model: gpt-4o\n",
      "‚úÖ File `how_to_book.pdf` added to messages for analysis.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Your prompt:** \n",
       "Please analyze the YAML file and for each operational capability:\n",
       "1. Decribe name and decribes the an ARCADIA operartional process that delivers on a operational capbility for the system. \n",
       "2. Define the Activities that starts the process with the \"EBSD User\".\n",
       "3. Define the additinal activites that form the chain of activies that deliver the capability across the entities. \n",
       "    - Include for each activity the allocated entity.\n",
       "4. Each Activity shall have a name under less than 5 word starting with a action verb. \n",
       "5. Each Activity shall have a decription that can leverage the document provided.\n",
       "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
       " Format the response in .html format."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>Operational Capabilities Analysis</title>\n",
       "\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"capability\">\n",
       "<h2>Detailed Thermal Characterization</h2>\n",
       "<p><strong>Description:</strong> Provides nondestructive testing methods to accurately measure junction temperatures and characterize the internal thermal structure of electronic components.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Initiate Thermal Testing</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User initiates the thermal testing process using Simcenter Micred solutions to measure junction temperatures and characterize the internal thermal structure.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Measure Junction Temperatures</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Use Simcenter Micred solutions to perform nondestructive electrical tests compliant with JEDEC 51 standard, providing accurate junction temperatures and characterizing the internal thermal structure.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"capability\">\n",
       "<h2>Quick and Easy Testing</h2>\n",
       "<p><strong>Description:</strong> Utilizes thermal transient testing methods that are easy to apply, even for complex designs, and suitable for high-volume testing.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Start Transient Testing</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User starts the thermal transient testing process using Simcenter Micred solutions to quickly and easily test electronic components.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Apply Power Step</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Apply a power step to the device under test (DUT) to induce a thermal transient response, measuring the transient change of junction temperature accurately.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"capability\">\n",
       "<h2>Accurate Thermal Metrics</h2>\n",
       "<p><strong>Description:</strong> Delivers precise values for junction temperatures and thermal resistance metrics, compliant with JEDEC standards.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Gather Thermal Data</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User gathers thermal data using Simcenter Micred solutions to obtain accurate values for junction temperatures and thermal resistance metrics.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Analyze Thermal Metrics</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Analyze the thermal metrics data to ensure compliance with JEDEC standards, providing accurate information for product specification sheets.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"capability\">\n",
       "<h2>Future-Ready Testing</h2>\n",
       "<p><strong>Description:</strong> Supports testing for new designs and materials, including SiC and GaN devices, to meet the demands of emerging technologies.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Initiate Future Testing</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User initiates testing for new designs and materials using Simcenter Micred solutions to evaluate the thermal performance of future electronics.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Evaluate New Materials</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Evaluate the thermal performance of devices based on new materials such as SiC and GaN, ensuring readiness for future technologies.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"capability\">\n",
       "<h2>Automated Quality Assurance</h2>\n",
       "<p><strong>Description:</strong> Integrates with production lines for end-of-line testing, ensuring zero-defect production through automated thermal testing and quality binning.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Start Quality Testing</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User starts the automated quality assurance process using Simcenter Micred solutions to ensure zero-defect production.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Perform EoL Testing</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Perform end-of-line (EoL) testing to detect assembly errors and ensure the thermal quality of final products, integrating with the production line for automated testing.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"capability\">\n",
       "<h2>Active Power Cycling</h2>\n",
       "<p><strong>Description:</strong> Combines power cycling with thermal degradation monitoring to assess the reliability and lifetime of power electronics.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Initiate Power Cycling</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User initiates active power cycling tests using Simcenter Micred solutions to assess the reliability and lifetime of power electronics.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Monitor Degradation</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Monitor thermal and electrical degradation during power cycling tests to identify weak spots and improve design reliability.</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"capability\">\n",
       "<h2>Simulation Model Calibration</h2>\n",
       "<p><strong>Description:</strong> Enhances the accuracy of thermal simulation models by calibrating them with real-world measurement data.</p>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 1: Collect Measurement Data</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD User</p>\n",
       "<p><strong>Description:</strong> The EBSD User collects real-world measurement data using Simcenter Micred solutions to enhance the accuracy of thermal simulation models.</p>\n",
       "</div>\n",
       "<div class=\"activity\">\n",
       "<h3>Activity 2: Calibrate Simulation Models</h3>\n",
       "<p><strong>Allocated Entity:</strong> EBSD Software Application</p>\n",
       "<p><strong>Description:</strong> Calibrate thermal simulation models with collected measurement data to improve simulation accuracy and predict real-world performance.</p>\n",
       "</div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Token Usage Info:**\n",
       "\n",
       "Tokens used: prompt=11795, completion=1635, total=13430"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "#from capella_tools  import Open_AI_RAG_manager\n",
    "\n",
    "from capella_tools import Open_AI_RAG_manager\n",
    "\n",
    "\n",
    "    \n",
    "prompt = \"\"\"\n",
    "Please analyze the YAML file and for each operational capability:\n",
    "1. Decribe name and decribes the an ARCADIA operartional process that delivers on a operational capbility for the system. \n",
    "2. Define the Activities that starts the process with the \"EBSD User\".\n",
    "3. Define the additinal activites that form the chain of activies that deliver the capability across the entities. \n",
    "    - Include for each activity the allocated entity.\n",
    "4. Each Activity shall have a name under less than 5 word starting with a action verb. \n",
    "5. Each Activity shall have a decription that can leverage the document provided.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Get YAML content\n",
    "yaml_content = yaml_handler.get_yaml_content()\n",
    "\n",
    "# Step 2: Invoke ChatGPT for analysis\n",
    "analyzer = Open_AI_RAG_manager.ChatGPTAnalyzer(yaml_content)\n",
    "analyzer.add_text_file_to_messages(\"how_to_book.pdf\")\n",
    "analyzer.initial_prompt(prompt)\n",
    "chatgpt_response = analyzer.get_response()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab07e0f-6cdb-4b16-9c5b-0acd3e7944cd",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Execute Followup Prompts\n",
    "\n",
    "### Purpose\n",
    "This cell executes the **follow up prompts** defined for analyzing the model. These prompts can be added by the note book user in addition to the default prompts\n",
    "\n",
    "### What This Cell Does\n",
    "- Use the structured input file (e.g., `capella_model.yaml`).\n",
    "- Excutes the prompt defined in the cell.\n",
    "- Outputs the results directly in the notebook.\n",
    "\n",
    "### üõ†Ô∏è Instructions\n",
    "1. Ensure the `capella_model.yaml` file is generated and up-to-date.\n",
    "2. Run this cell to execute the default prompts.\n",
    "3. Review the output to verify the accuracy and relevance of the analysis.\n",
    "\n",
    "> üí° **Tip:** Modify the promt to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab94bcf-5ea3-4d7d-89e8-508dcd603d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzer.follow_up_prompt(\"Generate a report that could be used to develop and FMEA based on the Braking functonal chain.\")\n",
    "#chatgpt_response = analyzer.get_response()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ada9b-367c-4929-badf-e27c7170b825",
   "metadata": {},
   "source": [
    "## üí¨ Launch Interactive Chat on Structured Input\n",
    "\n",
    "### Purpose\n",
    "This cell launches an interactive chat session based on the structured input file, leveraging ARCADIA and Polarion terminology to ensure the analysis remains consistent with the modeling context.\n",
    "\n",
    "### Key Features\n",
    "- Uses the generated structured input file (e.g., `capella_model.yaml`) to guide the conversation.\n",
    "- Supports ARCADIA terms such as **functions**, **components**, **activities**, and **exchanges**.\n",
    "- Incorporates Polarion terms like **workitem**, **requirement**, and **traceability** for seamless integration with requirements management workflows.\n",
    "\n",
    "### How It Works\n",
    "1. The structured input file provides context for the chat session.\n",
    "2. You can interactively query details about the model elements, relationships, and dependencies.\n",
    "3. Responses are tailored using ARCADIA and Polarion terminology.\n",
    "\n",
    "### Example Prompts\n",
    "- **For ARCADIA:**\n",
    "  ```plaintext\n",
    "  What are the dependencies and exchanges for the selected function in the Logical Architecture phase?\n",
    "\n",
    "- **For Polarion:**\n",
    "  ```plaintext\n",
    "  Provide the traceability matrix for the workitem linked to this component.\n",
    "  ```\n",
    "### üõ†Ô∏è Instructions\n",
    "1. Ensure the `capella_model.yaml` file has been generated and is up-to-date.\n",
    "2. Run this cell to start the interactive chat session.\n",
    "3. Enter your queries using **ARCADIA** or **Polarion** terms for accurate and relevant responses.\n",
    "\n",
    "### üìù Notes\n",
    "- The interactive chat dynamically adapts to the content in the structured input file.\n",
    "- Use precise and contextual queries to ensure the best results and insights.\n",
    "\n",
    "> üí° **Tip:** If you're unfamiliar with ARCADIA or Polarion terminology, consult the respective documentation or glossary for guidance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654576ab-fb68-45e8-bf4c-1931c1c0c9ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ScannerError",
     "evalue": "mapping values are not allowed here\n  in \"<unicode string>\", line 18, column 48:\n     ... etailed Thermal Characterization:\n                                         ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapella_model.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     yaml_content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 6\u001b[0m n2 \u001b[38;5;241m=\u001b[39m \u001b[43mN2DiagramGenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN2DiagramGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLAB Brake Diagram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctional\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m n2\u001b[38;5;241m.\u001b[39mrun_all()\n\u001b[1;32m     10\u001b[0m n2 \u001b[38;5;241m=\u001b[39m N2DiagramGenerator\u001b[38;5;241m.\u001b[39mN2DiagramGenerator(yaml_content, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAB Brake Diagram\u001b[39m\u001b[38;5;124m\"\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/capella_tools/N2DiagramGenerator.py:29\u001b[0m, in \u001b[0;36mN2DiagramGenerator.__init__\u001b[0;34m(self, yaml_content, diagram_name, mode)\u001b[0m\n\u001b[1;32m     26\u001b[0m yaml\u001b[38;5;241m.\u001b[39madd_constructor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!uuid\u001b[39m\u001b[38;5;124m\"\u001b[39m, uuid_constructor, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mSafeLoader)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiagram_name \u001b[38;5;241m=\u001b[39m diagram_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Exchange Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myaml_data \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msafe_load\u001b[39m(stream):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    to be safe for untrusted input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[0;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     80\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[0;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m     84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:111\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    109\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceEndEvent):\n\u001b[0;32m--> 111\u001b[0m     node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    113\u001b[0m end_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[1;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     80\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_scalar_node(anchor)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[0;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m     84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:111\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    109\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceEndEvent):\n\u001b[0;32m--> 111\u001b[0m     node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    113\u001b[0m end_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/composer.py:127\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m anchor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors[anchor] \u001b[38;5;241m=\u001b[39m node\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMappingEndEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m#key_event = self.peek_event()\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/parser.py:428\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_block_mapping_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeyToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    429\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(KeyToken, ValueToken, BlockEndToken):\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mchoices):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_more_tokens():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens:\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/scanner.py:223\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Is it the value indicator?\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_value():\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Is it an alias?\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/yaml/scanner.py:577\u001b[0m, in \u001b[0;36mScanner.fetch_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# We are allowed to start a complex value if and only if\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# we can start a simple key.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_simple_key:\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmapping values are not allowed here\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mark())\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# If this value starts a new block mapping, we need to add\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# BLOCK-MAPPING-START.  It will be detected as an error later by\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# the parser.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n",
      "\u001b[0;31mScannerError\u001b[0m: mapping values are not allowed here\n  in \"<unicode string>\", line 18, column 48:\n     ... etailed Thermal Characterization:\n                                         ^"
     ]
    }
   ],
   "source": [
    "from capella_tools  import N2DiagramGenerator\n",
    "# Example: Using the class with YAML content and a diagram name\n",
    "with open(\"capella_model.yaml\", \"r\") as f:\n",
    "    yaml_content = f.read()\n",
    "\n",
    "n2 = N2DiagramGenerator.N2DiagramGenerator(yaml_content, \"LAB Brake Diagram\",mode=\"functional\" )\n",
    "n2.run_all()\n",
    "\n",
    "\n",
    "n2 = N2DiagramGenerator.N2DiagramGenerator(yaml_content, \"LAB Brake Diagram\",mode=\"component\")\n",
    "n2.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d370a-fcf4-4084-9064-f5e11a03a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.interactive_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dea895-123c-4c7f-b386-89510fcfcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2484d-c283-416d-b5ae-03289fc2a8a1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c59542-ddf7-4047-9007-2613a7f96589",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddd2fe-aeef-43a8-94d2-4b7cac1ce700",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
